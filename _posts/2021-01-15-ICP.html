---
layout: post
title: "2D Iterative Closest Point (ICP)"
subtitle: "ICP using c++ and eigen library"
date: 2020-01-26 23:45:13 -0400
background: '/img/posts/01.jpg'
---

<p>
This work is based on the work of <a href=‚Äùhttps://nbviewer.org/github/niosus/notebooks/blob/master/icp.ipynb‚Äù> Igor Bongoslavskyi </a>.
</p>

<p>ICP is an algorithm used to compute the rotation and the transformation ( rotation \(R\) and translation \(t\) )
     between two sets of points, which target points \(P = \{p_i\}\) and references points \(Q = \{q_i\}\), 
    where it uses and minimizing the differences of the two group of points. For example, ICP use in 3D reconstruction point cloud, 
    or in 2D to match between scanning (for robot localizations)</p>

<p>In this projects I wrote a ICP using C++ and Eigne template. I used cv-Plot to show a visualization presentation of the points. 
    <a href=‚Äùhttps://github.com/Profactor/cv-plot‚Äù target="_blank" rel="noopener noreferrer" >CV-Plot </a> is a library developed using purely opencv that can work in real time with easy integration.</p>

    <h2 class="section-heading">ICP algorithms</h2>

<p> 
    In this project I used different algorithms which: (1) ICP based on SVD (2) ICP based on nonlinear least square. 
</p>

<p> 
    First I will start with SVD_ICP algorithms where there are five steps to do the ICP which are.
</p>

<ul>
    <li>Computer center data and transform them </li>
    <li>Compute correspondences</li>
    <li>Compute cross covariance matrix</li>
    <li>Find  \(ùëÖ\)  and  \(ùë°\)  from SVD decomposition</li>
    <li>Apply transformation and computer error</li>
</ul> 

<p>
    I will show the code and explain it for each steps. Before we start it is important to
     define the data type will be used in programming. 
    So starting by defineing the point I use Eigen template Vector2d to store the value of the point \((x,y)\). 
    And I used std::vectore to store the list of the point. I used Eigen::MatrixXd to process the rotation matrix and translation. 
    Note: using Eigen library we need to keep the definition of variable constant.</p>


<h3 class="section-heading">Computer center data and transform them </h3>

<p>
    In this step we compute the mean center of all points in targets \(\overline P=\frac{1}{n}\sum_{i=1}^n p_i\) and 
    references \(\overline Q=\frac{1}{n}\sum_{i=1}^n q_i\). 
    After computing center of each point we reduce thier coordinate
     \(p^{'} = p_i - \overline P\) and \(q^{'} = q_i - \overline Q\).
</p>

<p>
    The data used to test this projects is hand made data \(Q\) then a transformation applied to create the targets set \(P\).
</p>


<img src="{{site.baseurl}}/assets/icp/Data.PNG">

<p>
    The function of computing the center of the points is shown below.
     The inpute is a vector contain the list of points in Eigen::Vector2d format and the output is Eigen::Vector2d as well.
</p>
{% highlight ruby %}
Eigen::Vector2d Center_data(vector<Eigen::Vector2d> P)
{
	Eigen::Vector2d temp;
	temp << 0, 0;
	for (int i = 0; i < P.size(); i++)
	{
		temp += P[i];
	}
	temp = temp / P.size();
	return temp;
}
{% endhighlight %}

<p>After computing the center of data or the mean, we reduce the coordinate of the points using the following code</p>

{% highlight ruby %}
for (int i = 0; i < Q.size(); i++)
	{
		Q_centered.push_back(Q[i] - center_of_Q);
	}
{% endhighlight %}

<p>The output of transformation show below</p>

<img src="{{site.baseurl}}/assets/icp/reduce coordinate.PNG">

<p>We can see how the target points \(P\) move to the center of refrence points \(Q\).</p>

<h3 class="section-heading">Compute correspondences</h3>
<p>Now we need to compute the correspondences between the target points and reference points. At this point there many 
    algorithms we can use to do the matching such as search Tree and ANN. 
    Correspondences algorithms also known by the name of Registration algorithms. 
    To measure the matched point I am going to use linalg_norm to calculate the normal vector. 
    The function is show below where the inpute is Vector2d and the output is the differencess.
</p>

{% highlight ruby %}
double linalg_norm(Eigen::Vector2d p) {
	return sqrt(p(0) * p(0) + p(1) * p(1));
}
{% endhighlight %}

<p>
    The correspondences algorithms consiste of two loops where the first loop is to go through the point in refrence point \(Q\),
    and the second loop to go through the targets points \(P\). Each point is measured using linalg_norm and compared it with the minimumvalue.
    Then the indexs of both the target points and the reference points stored in vector. The function is show below where two vectors is the input 
    and the output is a vector contain the matched indexes. 
</p>

{% highlight ruby %}
vector<Eigen::Vector2d> Get_correspondence_indices(vector<Eigen::Vector2d> P, vector<Eigen::Vector2d> Q)
{
	vector<Eigen::Vector2d> correspondences;
	for (int i = 0; i < P.size(); i++)
	{
		double min_distance = 99999999.9;
		int match_index = -1;
		for (int j = 0; j < Q.size(); j++)
		{
			double distance = linalg_norm(Q[j] - P[i]);
			if (distance < min_distance)
			{
				match_index = j;
				min_distance = distance;
			}
		}
		if (match_index != -1)
		{
			Eigen::Vector2d temp;
			temp << i, match_index;
			correspondences.push_back(temp);
		}
	}
	return correspondences;
}
{% endhighlight %}

<p>
    The figure below shows the output of the correspondences process, where each point from the reference points \(Q\) is linked to the target points \(P\).
    As can be seen the matching process is not a great one, but it do the work for a 2D and small points set.
</p>


<img src="{{site.baseurl}}/assets/icp/correspondeces.jpg">

<h1 class="section-heading">Compute cross covariance matrix</h1>
<p>
    Now we need to compute the cross covariance \(K\) between the correspondeces points.
</p>

$$K=E[(q_i - \overline Q)(p_i - \overline P)^T)] $$
$$ =\frac{1}{N} \sum(q_i - \overline Q)(p_i - \overline P)^T) $$
$$ \approx \sum(q_i - \overline Q)(p_i - \overline P)^T) $$

<p>
    The output of this equation \(K\) will be a mratix of \(2x2\), due to that \(p_i , q_j \in \Bbb R^2\).
</p>

$$K = \begin{pmatrix}cov(p_{xi},q_{xj}) & cov(p_{xi},q_{yj})\\\ cov(p_{yi},q_{xj}) & cov(p_{yi},q_{yj})\end{pmatrix}$$

<p>
    After computing the covariance, we will compute \(R\) and \(t\) using Singular Value Decompositions SVD.
    SVD of matrix is a factorization of the matrix. Where the output of SVD is three matrixs which \(S\), \(U\), and \(T_V\).
    Therefore, \(R=UV^T\) and \(t=\mu_Q - R_{\mu_P}\). Using Eigen library we will compute the SVD of cov using Eigen::JacobiSVD, 
    then we will compute the rotation and translation as shown in the below snap code.
</p>

{% highlight ruby %}
// Step 4: Find  ùëÖ  and  ùë°  from SVD decomposition
Eigen::JacobiSVD<Eigen::MatrixXd> svd(cov, Eigen::ComputeFullU | Eigen::ComputeFullV);
auto R_found = svd.matrixU() * svd.matrixV().transpose();
auto T_found = center_of_Q - R_found * center_of_P;
{% endhighlight %}


<h1 class="section-heading">Apply transformation and computer error</h1>

<p>
    After getting the new \(R\) and \(t\), we need to apply the transformation to the target points \(P\).
    Using the following function Apply_transform(). The output of the function is a vector contain a list of 
    corrected points. After that the Error is computed using linalg_norm function \(E={\sqrt {P^{'} - Q} }\). 
    Finally, we repeat the same step for few time until the error reach to threshold. The function below is the ICP_SVD 
    that used. The function take four inputs which is two for reference points and target points, the vector take the error 
    at each iterations and the number of iterations.
</p>

{% highlight ruby %}
vector<Eigen::Vector2d> ICP_svd(vector<Eigen::Vector2d> P, 
                                vector<Eigen::Vector2d> Q, 
                                vector<double>& error, 
                                int iterations = 10)
    {
        // Step 1: computer center data and transform them 
        Eigen::Vector2d center_of_Q = Center_data(Q);
        vector<Eigen::Vector2d> Q_centered;
        for (int i = 0; i < Q.size(); i++)
        {
            Q_centered.push_back(Q[i] - center_of_Q);
        }
        vector<Eigen::Vector2d> P_copy = P;
        // Start the loop
        for (int iter = 0; iter < iterations; iter++)
        {
            Plot_data(P_copy, Q);
    
            vector<Eigen::Vector2d> P_centered;
            Eigen::Vector2d center_of_P = Center_data(P_copy);
            for (int i = 0; i < P.size(); i++)
            {
                P_centered.push_back(P_copy[i] - center_of_P);
            }
    
            // Step 2: Compute correspondences
            auto correspondences = Get_correspondence_indices(P_centered, Q_centered);
    
            // Step 3: compute_cross_covariance
            auto cov = compute_cross_covariance(P_centered, Q_centered, correspondences);
    
            // Step 4: Find  ùëÖ  and  ùë°  from SVD decomposition
            Eigen::JacobiSVD<Eigen::MatrixXd> svd(cov, Eigen::ComputeFullU | Eigen::ComputeFullV);
            auto R_found = svd.matrixU() * svd.matrixV().transpose();
            auto T_found = center_of_Q - R_found * center_of_P;
    
            // Step 5: Apply transformation and computer error
            P_copy = Apply_transform(P_copy, R_found, T_found);
            double _error = Compute_Square_difference(P_copy, Q);
            error.push_back(_error);
            cout << "Squared diff: (P_corrected - Q) = " << _error << endl;
        }
        Plot_data(P_copy, Q, 400);
        return P_copy;
    }
{% endhighlight %}

<p>
    The figures below shows the output if ICP_SVD algorithms and the error. 
    As can be seen the algorithm took 7 iteration to drop the error to zero and match the two points sets.
</p>

<img src="{{site.baseurl}}/assets/icp/icp_svd.gif">
<img src="{{site.baseurl}}/assets/icp/CPI_SVD_ERROR.jpg">

<<<<<<< HEAD
<h1 class="section-heading">ICP non-linear Least Square</h1>
=======

<h1 class="section-heading">ICP based on nonlinear least square</h1>

<p>
    In this problem we are working to reduce the error of the sum square distance between two points.
</p>

$$E = \sum[R*p_i + t - q_i]$$

<p>
    \(E\) is the value should be minimise by updating \(R, t\). 
    Keep note that \(P\) is the only one update and due to the present of \(R\) in 
    the equation this function is non linear. 
</p>

<p>
    The minimizing problem start with computing the corresponde point between both set. 
    We assume the pose is descripe as follow \(\mathbf{x} = [x,y,\theta]^T\) where \(\theta\) 
    place in the the rotation matrix \(R = \begin{pmatrix} cos(\theta) & -sin(\theta)\\\ sin(\theta) & cos(\theta)\end{pmatrix}\). 
    
</p>







>>>>>>> a80dbd9cad14843781aa2b974825c92a6c6e5c31
<p>
    As can be shown above we solve the problem of matching using SVD
     but there are other moethods that are more efficient. Instead solving the SVD 
     we try to minimise the error between the correspondeces points. 
</p>

$$
E = \sum_{i}[Rp_i + t - q_i]^2
$$

<p>
    For the minimizing we update \(R, t\) which will be represent in a vector \(x=[x,y,\theta]^T\), 
    where \(R=\begin{pmatrix}cos(\theta) & -sin(\theta))\\\ sin(\theta) & -cos(\theta))\end{pmatrix}\) 
    and \(t = \begin{pmatrix} x \\\ y\end{pmatrix}\). 
    We will keep update the target points \(p\) until overlap on the reference point \(Q\).
     Due to the present of \(R\) the problem become non-linear. 
</p>

<p>
    To solve this problem we will use Gauss Newton Method to minimise between the correspondeces points.
     Therefore the error is the sum of the error between the correspondese points. 
    Which is shown the equation below.
</p>
$$
    e(x) = \sum_{i,j} e_{i,j}(x)
$$
<p>
    Keep in mind that \(i,j\) refere to the correspondeces points between \(P\) and \(Q\) sets. 
</p>
$$
    e_{i,j}(x) = R_{\theta}p_i + t - q_j
$$

<p>
    Therefore, we need to minimize the error function \(E(x)\). 
</p>


$$
    {min}_x \to {\sum_{i,j} ||R_{\theta}p_i + t - q_j||^2}
$$

<p>
    let \(h_i(x) = R_{\theta}p_i + t\). The error function becom
</p>

$$
    {min}_x \to {\sum_{i,j} ||h(x) - q_j||^2}
$$

<p>
    To compute the the local minimume value we will use Hessian matrix which is a square martix (n x n) of second-order partial derivative of a function 
    <a href="https://machinelearningmastery.com/a-gentle-introduction-to-hessian-matrices/" target="_blank" rel="noopener noreferrer">see for more information </a>
</p>
$$ 
    H\Delta x = -E^{'} (x) 
$$
<p>
    And \(\Delta x\ = [\Delta x, \Delta, y, \Delta \theta]\) which represent the small change in \(x\).
    Therefore the error function become
</p>

$$
    E^{'}(x) = J(x)e(x)
$$

<p>
    \(J(x)\) is the jacobian and it show below
</p>

$$
   J = \begin{pmatrix}1 & 0 & -sin(\theta){p_i}^x-cos(\theta){p_i}^y)\\\ 0 & 1 & cos(\theta){p_i}^x-sin(\theta){p_i}^y)\end{pmatrix}
$$

<p>
    The code below shows a function create the jacobian using Eigen::MatrixXd that generate a matrix size (2x3).
</p>


{% highlight ruby %}
Eigen::MatrixXd Jacobian(Eigen::Vector3d _x, Eigen::Vector2d point)
{
	double angle = _x(2);
	double x = point(0);
	double y = point(1);
	Eigen::MatrixXd J(2, 3);
	J << 1, 0, -sin(angle) * x - cos(angle) * y,
		0, 1, cos(angle)* x - sin(angle) * y;

	return J;
}

Eigen::Vector2d Error(Eigen::Vector3d x, Eigen::Vector2d p, Eigen::Vector2d q)
{
	auto rotation = Get_R(x(2));
	Eigen::Vector2d translation;
	translation << x(0), x(1);
	auto prediction = rotation * p - translation;
	return (prediction - q);
}
{% endhighlight %}

<p>
    Now we can solve Hessian \(H = \begin{pmatrix} 0 & 0& 0\\\ 0 & 0& 0\\\ 0 & 0& 0 \end{pmatrix}\) 
    and \(g =\begin{pmatrix} 0 \\\ 0 \\\ 0 \end{pmatrix}\). Therefore to solve the system we create a 
    function call Prepare_system to compute Hessian matrix.
</p>

<p>
    The function Prepare_system take 7 inputs which are \(x\), Point set \(P\) and \() Q\), the correspondences indexs vectors,
    H materix, g vector and the error chi. The last 3 variables updated and returned using pass by reference.
</p>
<p>
    the function loop on all correspondence points to compute the Jacobian then update the H and g. Where \(H= J^T J\) and 
    \(g=J^T e\). Note that the \(weight\) is used to elementate the outliear point that above the threshold.
</p>
{% highlight ruby %}
void Prepare_system(Eigen::Vector3d x,
	vector<Eigen::Vector2d> P,
	vector<Eigen::Vector2d> Q,
	vector<Eigen::Vector2d> correspondences,
	Eigen::MatrixXd& H,
	Eigen::Vector3d& g,
	double& chi)
{
	for (int i = 0; i < correspondences.size(); i++)
	{
		auto p_point = P[correspondences[i](0)];
		auto q_point = Q[correspondences[i](1)];
		auto e = Error(x, p_point, q_point);
		double weight = Kernal(10, e);
		auto J = Jacobian(x, p_point);
		H += weight * J.transpose() * J;
		g += weight * J.transpose() * e;
		chi += e.transpose() * e;
	}
}
{% endhighlight %}

<h1 class="section-heading">ICP non-linear Least Square</h1>
<h2 class="subsection-heading">ICP non-linear Least Square</h2>

<p>
    ICP based on non-linear least square has four steps whicg shown in the code below.
    The first step is to initilize the for loop for the limited iteration. then 
    we initilize the x vector that contant the translation and \(\theta\). Also,
    Hessian matrix \(H\) and \(g\) initilized with zeros.
</p>
<p>
    We start processing the point by computing the correspondese point using the function define above.
    after we pass the data to Prepare_system function to compute Hessain matrix \(H\) and \(g\).
    Using \(H\) and \(g\) we solve the equation using Eigen inbuild function 
    <a href="eigen.tuxfamily.org/dox/classEigen_1_1BDCSVD.html" target="_blank" rel="noopener noreferrer">bdcSvd</a>.
    the output of bdcSvd \(\delta x\) is the small motion computed between the both points group. 
</p>
<p>
    Using \(\delta x\) to update the overall \(x\) and then computer \(R\) and \(t\). 
    The target point then updated using the descibe function Apply_transform and the final 
    translation and rotation is updated as well using \(R_{final} = R * R_{final}\) and \(T_{final} += t\).
</p>

<p>
    Note that we use chi as a threshold where it stop when it reach below a certine value.
</p>
{% highlight ruby %}
vector<Eigen::Vector2d> ICP_least_squares(vector<Eigen::Vector2d> P, 
										  vector<Eigen::Vector2d> Q, 
										  vector<double>& error, 
										  int iterations = 10)
{
	Eigen::MatrixXd R_final = Eigen::MatrixXd::Identity(2, 2);
	Eigen::Vector2d T_final = Eigen::Vector2d::Zero();
	vector<Eigen::Vector2d> P_copy = P;
	for (int i = 0; i < iterations; i++)
	{
		Plot_data(P_copy, Q, 80);
		Eigen::Vector3d x = Eigen::Vector3d::Zero();
		Eigen::MatrixXd rot = Get_R(x(2));
		Eigen::Vector2d t;
		t(0) = x(0);
		t(1) = x(1);
		Eigen::MatrixXd H = Eigen::MatrixXd::Zero(3, 3);
		Eigen::Vector3d g = Eigen::Vector3d::Zero(3);
		double chi = 0.0;
		// step 1: compute correspondese 
		auto correspondences = Get_correspondence_indices(P_copy, Q);

		// step 2: compute H, g and Chi
		Prepare_system(x, P_copy, Q, correspondences, H, g, chi);
		error.push_back(chi);
		// Step 3: solve the linear equation
		Eigen::Vector3d dx = -1 * H.bdcSvd(Eigen::ComputeThinU | Eigen::ComputeThinV).solve(g);

		// step 4: update x and apply transformation
		x += dx;
		x(2) = atan2(sin(x(2)), cos(x(2)));
		rot = Get_R(x(2));
		t(0) = x(0);
		t(1) = x(1);
		P_copy = Apply_transform(P_copy, rot, t);
		R_final = rot * R_final;
		T_final += t;
		if (chi < 0.0001)
		{
			break;
		}
	}
	return P_copy;
}
{% endhighlight %}


<p>
    The figure below shows the output of ICP least square and the error output.
</p>


<img src="{{site.baseurl}}/assets/icp/ICP_least_square.gif">


<img src="{{site.baseurl}}/assets/icp/ICP_LSQ_ERROR.jpg">


<p>
    For the full code check this link <a href=‚Äù ‚Äù target="_blank" rel="noopener noreferrer"> Guthub_code </a>
</p>




<h1 class="section-heading">Refrences</h1>
<p>
    <a href=‚Äùgithub.com/thegyro/Project4-Scan-Matching‚Äù target="_blank" rel="noopener noreferrer"> Srinath Rajagopalan </a>   
</p>
<p>
    <a href=‚Äùhttps://pcl.readthedocs.io/projects/tutorials/en/latest/interactive_icp.html‚Äù target="_blank" rel="noopener noreferrer"> Link_1 </a>
</p>
<p>
    and the explination of <a href= "www.youtube.com/channel/UCi1TC2fLRvgBQNe-T4dp8Eg" target="_blank" rel="noopener noreferrer"> Cyrill Stachniss </a>
</p>
<p>
    <a href=‚Äùhttps://github.com/JyotiSunkara/ICP‚Äù target="_blank" rel="noopener noreferrer"></a> Jyoti Sunkara </a> 
</p>
<p>M. Greenspan and M. Yurick, "Approximate k-d tree search for efficient ICP," 
    Fourth International Conference on 3-D Digital Imaging and Modeling, 2003. 3DIM 2003. 
    Proceedings., 2003, pp. 442-448, doi: 10.1109/IM.2003.1240280.</p>