<!DOCTYPE html>
<!-- saved from url=(0083)http://127.0.0.1:4000/2021/06/06/Variaational-inference-Gaussian-mixture-model.html -->
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><link type="text/css" rel="stylesheet" id="dark-mode-custom-link"><link type="text/css" rel="stylesheet" id="dark-mode-general-link"><style lang="en" type="text/css" id="dark-mode-custom-style"></style><style lang="en" type="text/css" id="dark-mode-native-style"></style><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>
    Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha
    
  </title>

  <meta name="description" content="Variational inference methods in Bayesian inference and machine learning are techniques which are involved in approximating intractable integrals. Most of th...">

  <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link href="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/css" rel="stylesheet" type="text/css">
  <link href="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/css(1)" rel="stylesheet" type="text/css">

  <script src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/all.js" crossorigin="anonymous"></script>

  <link rel="stylesheet" href="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/main.css">
  <link rel="canonical" href="http://localhost:4000/2021/06/06/Variaational-inference-Gaussian-mixture-model.html">
  <link rel="alternate" type="application/rss+xml" title="Ashutosh Kushwaha" href="http://127.0.0.1:4000/feed.xml">

</head>


<body data-new-gr-c-s-check-loaded="14.1060.0" data-gr-ext-installed="">

  <!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-light fixed-top is-fixed" id="mainNav">
  <div class="container">
    <a class="navbar-brand" href="http://127.0.0.1:4000/">Ashutosh Kushwaha</a>
    <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      Menu
      <svg class="svg-inline--fa fa-bars fa-w-14" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="bars" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" data-fa-i2svg=""><path fill="currentColor" d="M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"></path></svg><!-- <i class="fa fa-bars"></i> Font Awesome fontawesome.com -->
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="http://127.0.0.1:4000/">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="http://127.0.0.1:4000/about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="http://127.0.0.1:4000/posts">Posts</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="http://127.0.0.1:4000/contact">Contact</a>
        </li>
      </ul>
    </div>
  </div>
</nav>


  <!-- Page Header -->

<header class="masthead" style="background-image: url(&#39;/img/posts/Gaussian/probability_distribution.png&#39;)">
  
    <div class="overlay"></div>
    <div class="container">
      <div class="row">
        <div class="col-lg-8 col-md-10 mx-auto">
          <div class="post-heading">
            <h1>Variational Inference Gaussian Mixture Model</h1>
            
            <h2 class="subheading">When point estimate does not work, Bayesian inference comes into picture</h2>
            
            <span class="meta">Posted by
              <a href="http://127.0.0.1:4000/2021/06/06/Variaational-inference-Gaussian-mixture-model.html#">Ashutosh Kushwaha</a>
              on June 06, 2021 Â· <span class="reading-time" title="Estimated read time">
  
   3 mins  read </span>

            </span>
          </div>
        </div>
      </div>
    </div>
  </header>

  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">

        <p>Variational inference methods in Bayesian inference and machine learning are techniques which are involved in approximating intractable integrals. Most of the machine learning techniques involves finding the point estimates (Maximum likelihood estimation (MLE), Maximum a posteriori estimate (MAP)) of the latent variables, parameters which certainly do not account for any uncertainty. For taking account of uncertainty in point estimates, an entire posterior distribution over the latent variables and parameters is approximated.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/2.png" alt=""></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p>For approximation of posterior distribution, which involves intractable integrals variational inference methods are applied for making the calculation tractable (having some kind of close form mathematically !!) i.e. which does not involve calculation of marginal distribution of the observed variables P(X).</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/3.png" alt="2"></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;</p>

<p>The marginalisation over Z to calculate P(X) is intractable, because of the search space of Z is combinatorially large, thus we seek an approximation, using variational distribution Q(Z) with itâs own variational parameters.</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;</p>

<h2 id="variational-inference-as-an-optimisation-problem">Variational Inference as an Optimisation problem</h2>

<p>Since we are trying to approximate a true posterior distribution p(Z|X) with Q(Z), a good choice of measure for measuring the dissimilarity between the true posterior and approximated posterior is KullbackâLeibler divergence (<strong>KL-divergence</strong>),</p>

<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/4.png" alt="2"></p>

<p>&nbsp;&nbsp;&nbsp;</p>

<p>which is basically expectation of difference in log of two probability distribution with respect to approximated distribution. Considering KL divergence as an optimisation function, it needs to be minimised with respect to variational parameters of the variational distribution Q(Z). Since calculating KL divergence itself involves the calculation of posterior distribution P(Z|X), the calculation of dissimilarity in-terms of KL divergence needs to be expressed where we come across <strong>Evidence lower bound</strong> (ELBO). The above expression KL divergence can be written in terms of ELBO as</p>

<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/5.png" alt="2"></p>

<p>in which log evidence log P(X) is constant with respect to Q(Z), maximising the term L(Q) (Evidence lower bound) minimises KL divergence. By choosing an appropriate choice of Q(Z), L(Q) becomes maximizable and tractable to compute.</p>

<h2 id="mean-field-approximation">Mean field approximation</h2>

<p>The mean field approximation assumes that all the hidden variables are independent of each other, which simplifies the joint distribution of hidden variables as the product of marginal distribution of each hidden variable.</p>

<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/6.png" alt="2"></p>

<p>where N is the no. of the hidden variables. It can be shown that best distribution qâ±¼(Zâ±¼) for maximising ELBO can be estimated as</p>

<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/7.png" alt="2"></p>

<p>which is expectation of log joint probability distribution of observed and latent variables taken over variables which do not include Zâ±¼. This type above equations can be simplified into functions of hyper-parameters of the prior distribution over the latent variable and expectation of the latent variables which is not being calculated. These type of equation create circular between the parameters of the distribution over the variables being calculated and expectation of variables not being calculated, this section of circular dependencies will be more clear in the following section. This circular dependence of distribution of parameters of the variational distribution suggest an iterative update procedure same as <strong>Expectation-Maximisation</strong> algorithm.</p>

<h1 id="variational-inference-in-gaussian-mixture-model">Variational inference in Gaussian mixture model</h1>
<p><img src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/8.png" alt="2" height="200px" width="20px"></p>



        <hr>

        <div class="clearfix">

          
          

        </div>

      </div>
    </div>
  </div>


  <!-- Footer -->

<hr>

<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-md-10 mx-auto">
        <ul class="list-inline text-center">
          
          <li class="list-inline-item">
            <a href="mailto:akushwaha9808@gmail.com">
              <span class="fa-stack fa-lg">
                <svg class="svg-inline--fa fa-circle fa-w-16 fa-stack-2x" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="circle" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8z"></path></svg><!-- <i class="fas fa-circle fa-stack-2x"></i> Font Awesome fontawesome.com -->
                <svg class="svg-inline--fa fa-envelope fa-w-16 fa-stack-1x fa-inverse" aria-hidden="true" focusable="false" data-prefix="far" data-icon="envelope" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" data-fa-i2svg=""><path fill="currentColor" d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"></path></svg><!-- <i class="far fa-envelope fa-stack-1x fa-inverse"></i> Font Awesome fontawesome.com -->
              </span>
            </a>
          </li>
          
          
          
          
          
          
        </ul>
        <p class="copyright text-muted">Copyright Â© Ashutosh Kushwaha 2022</p>
      </div>
    </div>
  </div>
</footer>


  <script src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/jquery-3.5.1.min.js"></script>
<script src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/bootstrap.bundle.min.js"></script>
<script src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/scripts.js"></script>

<script src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/scripts(1).js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="./Variational Inference Gaussian Mixture Model - Ashutosh Kushwaha_files/js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>






</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>